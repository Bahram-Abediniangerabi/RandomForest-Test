{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import train dataset\n",
    "df2_train= pd.read_csv(\"exercise_03_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nan of each column with the mean of columns \n",
    "X2=df2_train.iloc[:,:100].fillna(df2_train.iloc[:,:100].mean())\n",
    "y2=df2_train['y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nans for categorical values in training dataset\n",
    "\n",
    "X2 = X2.fillna(X2['x34'].value_counts().index[0])\n",
    "X2 = X2.fillna(X2['x35'].value_counts().index[0])\n",
    "X2 = X2.fillna(X2['x68'].value_counts().index[0])\n",
    "X2 = X2.fillna(X2['x93'].value_counts().index[0])\n",
    "\n",
    "# recheck the nans for categorical columns\n",
    "#print(X2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x34', 'x35', 'x68', 'x93']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mask for categorical columns\n",
    "categorical_feature_mask = X2.dtypes==object\n",
    "\n",
    "# Turn categorical columns into a list\n",
    "categorical_cols = X2.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "#Check the list of categorical columns\n",
    "categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.812330</td>\n",
       "      <td>-0.122672</td>\n",
       "      <td>65.391785</td>\n",
       "      <td>6.323478</td>\n",
       "      <td>-18.511031</td>\n",
       "      <td>2.122648</td>\n",
       "      <td>0.319472</td>\n",
       "      <td>7.650422</td>\n",
       "      <td>7.713315</td>\n",
       "      <td>2.789856</td>\n",
       "      <td>...</td>\n",
       "      <td>-144.208496</td>\n",
       "      <td>5.482352</td>\n",
       "      <td>12.211997</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.201565</td>\n",
       "      <td>-9.837196</td>\n",
       "      <td>-21.092011</td>\n",
       "      <td>4.671140</td>\n",
       "      <td>0.588994</td>\n",
       "      <td>-11.417083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.445312</td>\n",
       "      <td>-0.436077</td>\n",
       "      <td>12.981759</td>\n",
       "      <td>30.716674</td>\n",
       "      <td>-34.981679</td>\n",
       "      <td>-16.712862</td>\n",
       "      <td>0.530105</td>\n",
       "      <td>8.740222</td>\n",
       "      <td>56.044533</td>\n",
       "      <td>0.075118</td>\n",
       "      <td>...</td>\n",
       "      <td>148.348086</td>\n",
       "      <td>-6.083035</td>\n",
       "      <td>-5.098374</td>\n",
       "      <td>1</td>\n",
       "      <td>5.433036</td>\n",
       "      <td>91.724841</td>\n",
       "      <td>4.305371</td>\n",
       "      <td>4.329130</td>\n",
       "      <td>0.371513</td>\n",
       "      <td>8.474528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.927148</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>-29.096012</td>\n",
       "      <td>-20.176841</td>\n",
       "      <td>10.109713</td>\n",
       "      <td>-45.994005</td>\n",
       "      <td>0.618132</td>\n",
       "      <td>7.757838</td>\n",
       "      <td>-69.749060</td>\n",
       "      <td>-1.561335</td>\n",
       "      <td>...</td>\n",
       "      <td>-76.239072</td>\n",
       "      <td>0.200787</td>\n",
       "      <td>-7.174907</td>\n",
       "      <td>1</td>\n",
       "      <td>2.595005</td>\n",
       "      <td>-14.630603</td>\n",
       "      <td>-3.743052</td>\n",
       "      <td>-14.820376</td>\n",
       "      <td>-2.366675</td>\n",
       "      <td>2.613091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370.736586</td>\n",
       "      <td>-0.263338</td>\n",
       "      <td>-75.273905</td>\n",
       "      <td>-21.765844</td>\n",
       "      <td>-72.478339</td>\n",
       "      <td>-8.701108</td>\n",
       "      <td>0.332586</td>\n",
       "      <td>2.769763</td>\n",
       "      <td>-35.815423</td>\n",
       "      <td>5.230400</td>\n",
       "      <td>...</td>\n",
       "      <td>-283.535765</td>\n",
       "      <td>4.986738</td>\n",
       "      <td>-6.649765</td>\n",
       "      <td>1</td>\n",
       "      <td>4.349013</td>\n",
       "      <td>-53.825281</td>\n",
       "      <td>-12.243755</td>\n",
       "      <td>-4.257462</td>\n",
       "      <td>-0.352829</td>\n",
       "      <td>-9.641206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.775263</td>\n",
       "      <td>-0.270047</td>\n",
       "      <td>-40.486723</td>\n",
       "      <td>3.990431</td>\n",
       "      <td>-13.733621</td>\n",
       "      <td>-6.185321</td>\n",
       "      <td>-0.733206</td>\n",
       "      <td>-3.325673</td>\n",
       "      <td>-5.055036</td>\n",
       "      <td>-4.331587</td>\n",
       "      <td>...</td>\n",
       "      <td>76.282274</td>\n",
       "      <td>3.793349</td>\n",
       "      <td>-0.865512</td>\n",
       "      <td>1</td>\n",
       "      <td>4.432424</td>\n",
       "      <td>8.605707</td>\n",
       "      <td>-23.823016</td>\n",
       "      <td>-11.913495</td>\n",
       "      <td>-0.139055</td>\n",
       "      <td>-0.318227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1         x2         x3         x4         x5        x6  \\\n",
       "0   83.812330 -0.122672  65.391785   6.323478 -18.511031   2.122648  0.319472   \n",
       "1   -0.445312 -0.436077  12.981759  30.716674 -34.981679 -16.712862  0.530105   \n",
       "2   82.927148  0.075277 -29.096012 -20.176841  10.109713 -45.994005  0.618132   \n",
       "3  370.736586 -0.263338 -75.273905 -21.765844 -72.478339  -8.701108  0.332586   \n",
       "4   33.775263 -0.270047 -40.486723   3.990431 -13.733621  -6.185321 -0.733206   \n",
       "\n",
       "         x7         x8        x9    ...             x90       x91        x92  \\\n",
       "0  7.650422   7.713315  2.789856    ...     -144.208496  5.482352  12.211997   \n",
       "1  8.740222  56.044533  0.075118    ...      148.348086 -6.083035  -5.098374   \n",
       "2  7.757838 -69.749060 -1.561335    ...      -76.239072  0.200787  -7.174907   \n",
       "3  2.769763 -35.815423  5.230400    ...     -283.535765  4.986738  -6.649765   \n",
       "4 -3.325673  -5.055036 -4.331587    ...       76.282274  3.793349  -0.865512   \n",
       "\n",
       "   x93       x94        x95        x96        x97       x98        x99  \n",
       "0    1 -3.201565  -9.837196 -21.092011   4.671140  0.588994 -11.417083  \n",
       "1    1  5.433036  91.724841   4.305371   4.329130  0.371513   8.474528  \n",
       "2    1  2.595005 -14.630603  -3.743052 -14.820376 -2.366675   2.613091  \n",
       "3    1  4.349013 -53.825281 -12.243755  -4.257462 -0.352829  -9.641206  \n",
       "4    1  4.432424   8.605707 -23.823016 -11.913495 -0.139055  -0.318227  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHot Encoder on training dataset (X)  \n",
    "\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "X2[categorical_cols] = X2[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "X2[categorical_cols].head(10)\n",
    "\n",
    "# import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# instantiate OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features = categorical_feature_mask, sparse=False ) \n",
    "# categorical_features = boolean mask for categorical columns\n",
    "# sparse = False output an array not sparse matrix\n",
    "\n",
    "# apply OneHotEncoder on categorical feature columns\n",
    "X2_ohe = ohe.fit_transform(X2) # It returns an numpy array\n",
    "\n",
    "# turn X into dict\n",
    "X2_dict = X2.to_dict(orient='records') # turn each row as key-value pairs\n",
    "\n",
    "# show X_dict\n",
    "X2_dict\n",
    "\n",
    "# DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# instantiate a Dictvectorizer object for X\n",
    "dv_X2 = DictVectorizer(sparse=False) \n",
    "# sparse = False makes the output is not a sparse matrix\n",
    "\n",
    "# apply dv_X on X_dict\n",
    "X2_encoded = dv_X2.fit_transform(X2_dict)\n",
    "\n",
    "# show X_encoded\n",
    "X2_encoded\n",
    "\n",
    "# vocabulary\n",
    "vocab2 = dv_X2.vocabulary_\n",
    "\n",
    "# show vocab\n",
    "vocab2\n",
    "\n",
    "# Get dummies\n",
    "X2 = pd.get_dummies(X2, prefix_sep='_', drop_first=True)\n",
    "\n",
    "# X head\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x34', 'x35', 'x68', 'x93']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import testing dataset\n",
    "df2_test= pd.read_csv(\"exercise_03_test.csv\")\n",
    "\n",
    "# Fill nans for numerical columns with the meansin testing dataset\n",
    "df2_test=df2_test.fillna(df2_train.mean())\n",
    "\n",
    "# Fill nans for categorical values in testing dataset\n",
    "df2_test = df2_test.fillna(df2_test['x34'].value_counts().index[0])\n",
    "df2_test = df2_test.fillna(df2_test['x35'].value_counts().index[0])\n",
    "df2_test = df2_test.fillna(df2_test['x68'].value_counts().index[0])\n",
    "df2_test = df2_test.fillna(df2_test['x93'].value_counts().index[0])\n",
    "\n",
    "categorical_cols_test = df2_test.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.252886</td>\n",
       "      <td>-0.170668</td>\n",
       "      <td>20.710224</td>\n",
       "      <td>-13.409410</td>\n",
       "      <td>-20.148997</td>\n",
       "      <td>18.649383</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.799069</td>\n",
       "      <td>27.749853</td>\n",
       "      <td>0.457208</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.154991</td>\n",
       "      <td>-5.020444</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>1</td>\n",
       "      <td>12.202997</td>\n",
       "      <td>17.206558</td>\n",
       "      <td>-6.698424</td>\n",
       "      <td>10.669022</td>\n",
       "      <td>0.535953</td>\n",
       "      <td>0.794408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.496163</td>\n",
       "      <td>-0.065142</td>\n",
       "      <td>-1.423250</td>\n",
       "      <td>9.250107</td>\n",
       "      <td>-58.582435</td>\n",
       "      <td>-3.730727</td>\n",
       "      <td>0.469421</td>\n",
       "      <td>2.994060</td>\n",
       "      <td>-74.308495</td>\n",
       "      <td>6.637583</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.797446</td>\n",
       "      <td>-2.605834</td>\n",
       "      <td>4.222651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865352</td>\n",
       "      <td>-31.330463</td>\n",
       "      <td>9.030439</td>\n",
       "      <td>1.769777</td>\n",
       "      <td>-0.265219</td>\n",
       "      <td>-2.511831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-46.054317</td>\n",
       "      <td>-0.174997</td>\n",
       "      <td>9.167775</td>\n",
       "      <td>7.611975</td>\n",
       "      <td>-33.043372</td>\n",
       "      <td>-2.258558</td>\n",
       "      <td>-0.308114</td>\n",
       "      <td>-8.216299</td>\n",
       "      <td>-10.016635</td>\n",
       "      <td>-2.693126</td>\n",
       "      <td>...</td>\n",
       "      <td>-246.457481</td>\n",
       "      <td>-3.404679</td>\n",
       "      <td>-4.384774</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.693588</td>\n",
       "      <td>-12.767262</td>\n",
       "      <td>-8.578260</td>\n",
       "      <td>0.202378</td>\n",
       "      <td>-0.901658</td>\n",
       "      <td>0.340148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.784201</td>\n",
       "      <td>-0.201334</td>\n",
       "      <td>24.985110</td>\n",
       "      <td>21.561477</td>\n",
       "      <td>5.953458</td>\n",
       "      <td>9.298979</td>\n",
       "      <td>0.061949</td>\n",
       "      <td>-1.028978</td>\n",
       "      <td>-46.827620</td>\n",
       "      <td>3.482482</td>\n",
       "      <td>...</td>\n",
       "      <td>301.527167</td>\n",
       "      <td>1.474712</td>\n",
       "      <td>6.158162</td>\n",
       "      <td>1</td>\n",
       "      <td>3.072433</td>\n",
       "      <td>41.619199</td>\n",
       "      <td>-0.255531</td>\n",
       "      <td>1.704807</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>-9.247276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.692351</td>\n",
       "      <td>-0.602332</td>\n",
       "      <td>-16.602345</td>\n",
       "      <td>41.147584</td>\n",
       "      <td>9.405121</td>\n",
       "      <td>-59.245570</td>\n",
       "      <td>-0.524156</td>\n",
       "      <td>-6.817356</td>\n",
       "      <td>17.554925</td>\n",
       "      <td>4.143827</td>\n",
       "      <td>...</td>\n",
       "      <td>208.742875</td>\n",
       "      <td>3.752589</td>\n",
       "      <td>2.435466</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.313370</td>\n",
       "      <td>-18.762901</td>\n",
       "      <td>-14.614473</td>\n",
       "      <td>17.928303</td>\n",
       "      <td>0.355491</td>\n",
       "      <td>7.571392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1         x2         x3         x4         x5        x6  \\\n",
       "0  120.252886 -0.170668  20.710224 -13.409410 -20.148997  18.649383  0.015563   \n",
       "1  151.496163 -0.065142  -1.423250   9.250107 -58.582435  -3.730727  0.469421   \n",
       "2  -46.054317 -0.174997   9.167775   7.611975 -33.043372  -2.258558 -0.308114   \n",
       "3   -7.784201 -0.201334  24.985110  21.561477   5.953458   9.298979  0.061949   \n",
       "4  -16.692351 -0.602332 -16.602345  41.147584   9.405121 -59.245570 -0.524156   \n",
       "\n",
       "         x7         x8        x9    ...            x90       x91       x92  \\\n",
       "0  0.799069  27.749853  0.457208    ...     -42.154991 -5.020444  0.142960   \n",
       "1  2.994060 -74.308495  6.637583    ...     -98.797446 -2.605834  4.222651   \n",
       "2 -8.216299 -10.016635 -2.693126    ...    -246.457481 -3.404679 -4.384774   \n",
       "3 -1.028978 -46.827620  3.482482    ...     301.527167  1.474712  6.158162   \n",
       "4 -6.817356  17.554925  4.143827    ...     208.742875  3.752589  2.435466   \n",
       "\n",
       "   x93        x94        x95        x96        x97       x98       x99  \n",
       "0    1  12.202997  17.206558  -6.698424  10.669022  0.535953  0.794408  \n",
       "1    1   0.865352 -31.330463   9.030439   1.769777 -0.265219 -2.511831  \n",
       "2    1  -7.693588 -12.767262  -8.578260   0.202378 -0.901658  0.340148  \n",
       "3    1   3.072433  41.619199  -0.255531   1.704807  0.514364 -9.247276  \n",
       "4    1  -3.313370 -18.762901 -14.614473  17.928303  0.355491  7.571392  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHot Encoder on testing dataset (df_test) \n",
    "\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "df2_test[categorical_cols] = df2_test[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "df2_test[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "# import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# instantiate OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features = categorical_feature_mask, sparse=False ) \n",
    "# categorical_features = boolean mask for categorical columns\n",
    "# sparse = False output an array not sparse matrix\n",
    "\n",
    "# apply OneHotEncoder on categorical feature columns\n",
    "df2_test_ohe = ohe.fit_transform(df2_test) # It returns an numpy array\n",
    "\n",
    "# turn X into dict\n",
    "df2_test_dict = df2_test.to_dict(orient='records') # turn each row as key-value pairs\n",
    "\n",
    "# show X_dict\n",
    "df2_test_dict\n",
    "\n",
    "# DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# instantiate a Dictvectorizer object for X\n",
    "dv_df2_test = DictVectorizer(sparse=False) \n",
    "# sparse = False makes the output is not a sparse matrix\n",
    "\n",
    "# apply dv_X on X_dict\n",
    "df2_test_encoded = dv_df2_test.fit_transform(df2_test_dict)\n",
    "\n",
    "# show X_encoded\n",
    "df2_test_encoded\n",
    "\n",
    "# vocabulary\n",
    "vocab_df2_test = dv_df2_test.vocabulary_\n",
    "\n",
    "# show vocab\n",
    "vocab_df2_test\n",
    "\n",
    "# Get dummies\n",
    "df2_test = pd.get_dummies(df2_test, prefix_sep='_', drop_first=True)\n",
    "\n",
    "# df_test head\n",
    "df2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireAnt\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    criterion='gini',\n",
    "    max_depth=5,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "roc_auc_score() missing 1 required positional argument: 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-53f8a982a1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_score_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_score_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: roc_auc_score() missing 1 required positional argument: 'y_score'"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
    "fprs, tprs, scores = [], [], []\n",
    "    \n",
    "for (train, test), i in zip(cv.split(X, y), range(5)):\n",
    "    clf.fit(X.iloc[train], y.iloc[train])\n",
    "    _, _, auc_score_train = compute_roc_auc(train)\n",
    "    fpr, tpr, auc_score = compute_roc_auc(test)\n",
    "    scores.append((auc_score_train, auc_score))\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "\n",
    "plot_roc_curve(fprs, tprs);\n",
    "pd.DataFrame(scores, columns=['AUC Train', 'AUC Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8648248403828026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "clf = RandomForestClassifier() #Initialize with whatever parameters you want to\n",
    "\n",
    "# 10-Fold Cross validation\n",
    "print (np.mean(cross_val_score(clf, X2, y2, cv=10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
